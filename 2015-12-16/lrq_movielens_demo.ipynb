{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JohnLangford/vowpal_wabbit/tree/master/demo/movielens\n",
    "\n",
    "Run 'make shootout' first to download data and generate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import subprocess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_linear_model_and_save_predictions():\n",
    "    train_file = 'ml-1m.ratings.train.vw'\n",
    "    test_file = 'ml-1m.ratings.test.vw'\n",
    "    cache_file = 'ml-1m.ratings.train.vw.cache'\n",
    "\n",
    "    cmd_train = \"vw --loss_function quantile -l 1 -b 24 --passes 100 -k --cache_file ml-1m.ratings.train.vw.cache -d ml-1m.ratings.train.vw --holdout_off --adaptive --invariant -f linear.model 2>&1\"\n",
    "    print subprocess.check_output(cmd_train, shell=True)\n",
    "    cmd_test = \"vw -d ml-1m.ratings.test.vw -t -i linear.model -p ml-1m.ratings.test.pred 2>&1\"\n",
    "    print subprocess.check_output(cmd_test, shell=True)\n",
    "    cmd_clean = \"rm -f *.cache\"\n",
    "    os.system(cmd_clean)\n",
    "    \n",
    "def linear_model_prediction_stat():\n",
    "    test_predictions_file = '/usr/local/vowpal_wabbit/demo/movielens/ml-1m.ratings.test.pred'\n",
    "    results = pd.read_csv(test_predictions_file, sep=' ',header=None)\n",
    "    results.columns = ['estimates', 'truth']\n",
    "    \n",
    "    print \"mean_squared_error for simple linear model:\" + str(mean_squared_error(results.truth, results.estimates))\n",
    "    print \"mean_absolute_error for simple linear model:\"+ str(mean_absolute_error(results.truth, results.estimates))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_linear_model_with_lrq_and_save_predictions():\n",
    "    train_file = 'ml-1m.ratings.train.vw'\n",
    "    test_file = 'ml-1m.ratings.test.vw'\n",
    "    cache_file = 'ml-1m.ratings.train.vw.cache'\n",
    "\n",
    "    cmd_train = \"vw --loss_function quantile -l 0.1 -b 24 --passes 100 -k --cache_file ml-1m.ratings.train.vw.cache -d ml-1m.ratings.train.vw --holdout_off --power_t 0.333 --l2 1.25e-7 --lrq um7 --adaptive --invariant -f lrq.model 2>&1\"\n",
    "    print subprocess.check_output(cmd_train, shell=True)\n",
    "    cmd_test = \"vw -d ml-1m.ratings.test.vw -t -i lrq.model -p ml-1m.ratings.test.lrq.pred 2>&1\"\n",
    "    print subprocess.check_output(cmd_test, shell=True)\n",
    "    cmd_clean = \"rm -f *.cache\"\n",
    "    os.system(cmd_clean)\n",
    "    \n",
    "def linear_model_with_lrq_prediction_stat():\n",
    "    test_predictions_file = '/usr/local/vowpal_wabbit/demo/movielens/ml-1m.ratings.test.lrq.pred'\n",
    "    results = pd.read_csv(test_predictions_file, sep=' ',header=None)\n",
    "    results.columns = ['estimates', 'truth']   \n",
    "    \n",
    "    print \"mean_squared_error for linear model with lrq:\" + str(mean_squared_error(results.truth, results.estimates))\n",
    "    print \"mean_absolute_error for linear model with lrq:\"+ str(mean_absolute_error(results.truth, results.estimates))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_linear_model_with_lrqdropout_and_save_predictions():\n",
    "    train_file = 'ml-1m.ratings.train.vw'\n",
    "    test_file = 'ml-1m.ratings.test.vw'\n",
    "    cache_file = 'ml-1m.ratings.train.vw.cache'\n",
    "\n",
    "    cmd_train = \"vw --loss_function quantile -l 0.45 -b 24 --passes 100 -k --cache_file ml-1m.ratings.train.vw.cache -d ml-1m.ratings.train.vw --holdout_off --lrq um14 --lrqdropout --adaptive --invariant -f lrq.dropout.model 2>&1\"\n",
    "    print subprocess.check_output(cmd_train, shell=True)\n",
    "    cmd_test = \"vw -d ml-1m.ratings.test.vw -t -i lrq.dropout.model -p ml-1m.ratings.test.lrq.dropout.pred 2>&1\"\n",
    "    print subprocess.check_output(cmd_test, shell=True)\n",
    "    cmd_clean = \"rm -f *.cache\"\n",
    "    os.system(cmd_clean)\n",
    "    \n",
    "def linear_model_with_lrqdropout_prediction_stat():\n",
    "    test_predictions_file = '/usr/local/vowpal_wabbit/demo/movielens/ml-1m.ratings.test.lrq.dropout.pred'\n",
    "    results = pd.read_csv(test_predictions_file, sep=' ',header=None)\n",
    "    results.columns = ['estimates', 'truth']\n",
    "    \n",
    "#     plt.scatter(x=results.truth, y=results.estimates)\n",
    "#     plt.xlabel('truth')\n",
    "#     plt.ylabel('estimates')\n",
    "#     plt.title('Estimates vs Truth (Movie ratings) - Linear Model With lrqdropout')      \n",
    "    \n",
    "    print \"mean_squared_error for linear model with lrqdropout:\" + str(mean_squared_error(results.truth, results.estimates))\n",
    "    print \"mean_absolute_error for linear model with lrqdropout:\"+ str(mean_absolute_error(results.truth, results.estimates))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = linear.model\n",
      "Num weight bits = 24\n",
      "learning rate = 1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = ml-1m.ratings.train.vw.cache\n",
      "Reading datafile = ml-1m.ratings.train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "2.000000   2.000000            1         1.0   4.0000   0.0000        3\n",
      "1.750061   1.500122            2         2.0   4.0000   0.9998        3\n",
      "1.501205   1.252350            4         4.0   4.0000   2.2839        3\n",
      "1.139968   0.778731            8         8.0   5.0000   3.1200        3\n",
      "0.762189   0.384409           16        16.0   4.0000   3.5570        3\n",
      "0.694471   0.626754           32        32.0   1.0000   2.9349        3\n",
      "0.573700   0.452929           64        64.0   2.0000   3.1922        3\n",
      "0.496200   0.418699          128       128.0   3.0000   3.5256        3\n",
      "0.493009   0.489817          256       256.0   3.0000   3.5509        3\n",
      "0.481259   0.469509          512       512.0   5.0000   3.5237        3\n",
      "0.473314   0.465369         1024      1024.0   1.0000   3.6218        3\n",
      "0.461307   0.449300         2048      2048.0   1.0000   3.0527        3\n",
      "0.455769   0.450231         4096      4096.0   4.0000   4.1753        3\n",
      "0.450800   0.445832         8192      8192.0   5.0000   3.5416        3\n",
      "0.446736   0.442672        16384     16384.0   2.0000   2.9170        3\n",
      "0.434327   0.421917        32768     32768.0   3.0000   4.2284        3\n",
      "0.419900   0.405473        65536     65536.0   2.0000   3.6943        3\n",
      "0.406721   0.393543       131072    131072.0   1.0000   3.2032        3\n",
      "0.394368   0.382015       262144    262144.0   4.0000   3.0431        3\n",
      "0.384212   0.374055       524288    524288.0   4.0000   4.0330        3\n",
      "0.375307   0.366402      1048576   1048576.0   4.0000   4.7169        3\n",
      "0.368864   0.362421      2097152   2097152.0   4.0000   3.3469        3\n",
      "0.363892   0.358921      4194304   4194304.0   5.0000   4.2746        3\n",
      "0.360118   0.356344      8388608   8388608.0   2.0000   2.2882        3\n",
      "0.357151   0.354184     16777216  16777216.0   5.0000   3.7096        3\n",
      "0.354784   0.352417     33554432  33554432.0   5.0000   4.1033        3\n",
      "0.352843   0.350902     67108864  67108864.0   5.0000   4.8073        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 995209\n",
      "passes used = 100\n",
      "weighted example sum = 9.95209e+07\n",
      "weighted label sum = 3.56378e+08\n",
      "average loss = 0.351905\n",
      "best constant = 3.58093\n",
      "total feature number = 298562700\n",
      "\n",
      "only testing\n",
      "Num weight bits = 24\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "predictions = ml-1m.ratings.test.pred\n",
      "using no cache\n",
      "Reading datafile = ml-1m.ratings.test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "0.942813   0.942813            1         1.0   4.0000   4.9710        3\n",
      "0.685011   0.427210            2         2.0   5.0000   4.3464        3\n",
      "0.921342   1.157673            4         4.0   5.0000   3.4842        3\n",
      "0.680000   0.438657            8         8.0   5.0000   4.4354        3\n",
      "1.072704   1.465409           16        16.0   5.0000   4.0765        3\n",
      "0.819233   0.565761           32        32.0   4.0000   3.2649        3\n",
      "0.660664   0.502095           64        64.0   4.0000   3.9555        3\n",
      "0.890695   1.120727          128       128.0   4.0000   3.5493        3\n",
      "0.964020   1.037345          256       256.0   2.0000   3.8380        3\n",
      "1.024520   1.085020          512       512.0   5.0000   3.3631        3\n",
      "0.974743   0.924965         1024      1024.0   4.0000   3.1138        3\n",
      "0.938786   0.902828         2048      2048.0   4.0000   4.3276        3\n",
      "0.972235   1.005684         4096      4096.0   5.0000   2.9261        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 5000\n",
      "passes used = 1\n",
      "weighted example sum = 5000\n",
      "weighted label sum = 18538\n",
      "average loss = 0.964595\n",
      "best constant = 3.70814\n",
      "total feature number = 15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_linear_model_and_save_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using l2 regularization = 1.25e-07\n",
      "final_regressor = lrq.model\n",
      "Num weight bits = 24\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.333\n",
      "decay_learning_rate = 1\n",
      "creating low rank quadratic features for pairs: um7 \n",
      "creating cache_file = ml-1m.ratings.train.vw.cache\n",
      "Reading datafile = ml-1m.ratings.train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "2.000000   2.000000            1         1.0   4.0000   0.0000        3\n",
      "1.964421   1.928843            2         2.0   4.0000   0.1423        3\n",
      "2.034112   2.103803            4         4.0   4.0000   0.3374        3\n",
      "1.885363   1.736614            8         8.0   5.0000   0.6308        3\n",
      "1.656303   1.427242           16        16.0   4.0000   1.0853        3\n",
      "1.228639   0.800976           32        32.0   1.0000   1.5397        3\n",
      "0.958031   0.687423           64        64.0   2.0000   2.3259        3\n",
      "0.733002   0.507974          128       128.0   3.0000   3.1115        3\n",
      "0.612450   0.491897          256       256.0   3.0000   3.5164        3\n",
      "0.538935   0.465420          512       512.0   5.0000   3.5289        3\n",
      "0.511542   0.484148         1024      1024.0   1.0000   3.4696        3\n",
      "0.510534   0.509527         2048      2048.0   1.0000   3.2376        3\n",
      "0.497726   0.484918         4096      4096.0   4.0000   4.3428        3\n",
      "0.491150   0.484573         8192      8192.0   5.0000   5.0000        3\n",
      "0.476974   0.462798        16384     16384.0   2.0000   3.2273        3\n",
      "0.452430   0.427885        32768     32768.0   3.0000   3.9059        3\n",
      "0.427965   0.403500        65536     65536.0   2.0000   3.9762        3\n",
      "0.408469   0.388974       131072    131072.0   1.0000   3.5315        3\n",
      "0.392510   0.376552       262144    262144.0   4.0000   3.2382        3\n",
      "0.380351   0.368192       524288    524288.0   4.0000   3.9184        3\n",
      "0.370239   0.360128      1048576   1048576.0   4.0000   4.6095        3\n",
      "0.359333   0.348427      2097152   2097152.0   4.0000   3.3202        3\n",
      "0.346549   0.333764      4194304   4194304.0   5.0000   4.1641        3\n",
      "0.333254   0.319959      8388608   8388608.0   2.0000   1.4713        3\n",
      "0.321475   0.309696     16777216  16777216.0   5.0000   3.5990        3\n",
      "0.312358   0.303241     33554432  33554432.0   5.0000   3.3174        3\n",
      "0.305988   0.299617     67108864  67108864.0   5.0000   4.8217        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 995209\n",
      "passes used = 100\n",
      "weighted example sum = 9.95209e+07\n",
      "weighted label sum = 3.56378e+08\n",
      "average loss = 0.303445\n",
      "best constant = 3.58093\n",
      "total feature number = 298562700\n",
      "\n",
      "only testing\n",
      "Num weight bits = 24\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "predictions = ml-1m.ratings.test.lrq.pred\n",
      "creating low rank quadratic features for pairs: (using dropout) um7 \n",
      "using no cache\n",
      "Reading datafile = ml-1m.ratings.test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "0.196449   0.196449            1         1.0   4.0000   4.4432        3\n",
      "0.518113   0.839777            2         2.0   5.0000   4.0836        3\n",
      "0.760315   1.002517            4         4.0   5.0000   3.5923        3\n",
      "0.658712   0.557108            8         8.0   5.0000   4.4598        3\n",
      "1.213354   1.767996           16        16.0   5.0000   4.1003        3\n",
      "0.932854   0.652354           32        32.0   4.0000   3.7679        3\n",
      "0.699523   0.466193           64        64.0   4.0000   3.7678        3\n",
      "0.854548   1.009572          128       128.0   4.0000   3.3772        3\n",
      "0.836044   0.817539          256       256.0   2.0000   2.7261        3\n",
      "0.895622   0.955201          512       512.0   5.0000   3.5918        3\n",
      "0.841439   0.787255         1024      1024.0   4.0000   3.5069        3\n",
      "0.810918   0.780397         2048      2048.0   4.0000   4.5870        3\n",
      "0.835018   0.859118         4096      4096.0   5.0000   2.9489        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 5000\n",
      "passes used = 1\n",
      "weighted example sum = 5000\n",
      "weighted label sum = 18538\n",
      "average loss = 0.83349\n",
      "best constant = 3.70814\n",
      "total feature number = 15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_linear_model_with_lrq_and_save_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = lrq.dropout.model\n",
      "Num weight bits = 24\n",
      "learning rate = 0.45\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating low rank quadratic features for pairs: (using dropout) um14 \n",
      "creating cache_file = ml-1m.ratings.train.vw.cache\n",
      "Reading datafile = ml-1m.ratings.train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "2.000000   2.000000            1         1.0   4.0000   0.0000        3\n",
      "1.836422   1.672843            2         2.0   4.0000   0.6543        3\n",
      "1.726044   1.615665            4         4.0   4.0000   1.4605        3\n",
      "1.410655   1.095267            8         8.0   5.0000   2.0668        3\n",
      "1.047915   0.685174           16        16.0   4.0000   2.6936        3\n",
      "0.817491   0.587067           32        32.0   1.0000   2.8394        3\n",
      "0.629399   0.441307           64        64.0   2.0000   3.0151        3\n",
      "0.524537   0.419675          128       128.0   3.0000   3.3180        3\n",
      "0.501815   0.479094          256       256.0   3.0000   3.4664        3\n",
      "0.486025   0.470236          512       512.0   5.0000   3.3948        3\n",
      "0.484644   0.483262         1024      1024.0   1.0000   3.3119        3\n",
      "0.482628   0.480612         2048      2048.0   1.0000   3.0702        3\n",
      "0.478346   0.474065         4096      4096.0   4.0000   3.8800        3\n",
      "0.475427   0.472507         8192      8192.0   5.0000   3.4857        3\n",
      "0.468170   0.460913        16384     16384.0   2.0000   3.0898        3\n",
      "0.455487   0.442804        32768     32768.0   3.0000   4.1906        3\n",
      "0.444440   0.433393        65536     65536.0   2.0000   4.1642        3\n",
      "0.430737   0.417034       131072    131072.0   1.0000   3.1813        3\n",
      "0.415808   0.400879       262144    262144.0   4.0000   2.2061        3\n",
      "0.400831   0.385855       524288    524288.0   4.0000   4.1581        3\n",
      "0.386029   0.371227      1048576   1048576.0   4.0000   4.5501        3\n",
      "0.370508   0.354987      2097152   2097152.0   4.0000   3.3098        3\n",
      "0.356227   0.341946      4194304   4194304.0   5.0000   4.3741        3\n",
      "0.344109   0.331991      8388608   8388608.0   2.0000   2.6343        3\n",
      "0.334352   0.324596     16777216  16777216.0   5.0000   3.4153        3\n",
      "0.326904   0.319455     33554432  33554432.0   5.0000   3.5960        3\n",
      "0.321475   0.316046     67108864  67108864.0   5.0000   4.6964        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 995209\n",
      "passes used = 100\n",
      "weighted example sum = 9.95209e+07\n",
      "weighted label sum = 3.56378e+08\n",
      "average loss = 0.31912\n",
      "best constant = 3.58093\n",
      "total feature number = 298562700\n",
      "\n",
      "only testing\n",
      "Num weight bits = 24\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "predictions = ml-1m.ratings.test.lrq.dropout.pred\n",
      "creating low rank quadratic features for pairs: (using dropout) um14 \n",
      "using no cache\n",
      "Reading datafile = ml-1m.ratings.test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "0.330412   0.330412            1         1.0   4.0000   4.5748        3\n",
      "0.165206   0.000000            2         2.0   5.0000   5.0000        3\n",
      "0.445387   0.725568            4         4.0   5.0000   3.7958        3\n",
      "0.297470   0.149554            8         8.0   5.0000   5.0000        3\n",
      "1.007795   1.718119           16        16.0   5.0000   4.0236        3\n",
      "0.803153   0.598512           32        32.0   4.0000   3.1099        3\n",
      "0.637003   0.470853           64        64.0   4.0000   3.6280        3\n",
      "0.835324   1.033644          128       128.0   4.0000   3.2645        3\n",
      "0.839406   0.843488          256       256.0   2.0000   2.8156        3\n",
      "0.899944   0.960482          512       512.0   5.0000   3.8238        3\n",
      "0.831357   0.762771         1024      1024.0   4.0000   3.4987        3\n",
      "0.809316   0.787275         2048      2048.0   4.0000   4.7699        3\n",
      "0.833645   0.857974         4096      4096.0   5.0000   3.0006        3\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 5000\n",
      "passes used = 1\n",
      "weighted example sum = 5000\n",
      "weighted label sum = 18538\n",
      "average loss = 0.829322\n",
      "best constant = 3.70814\n",
      "total feature number = 15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_linear_model_with_lrqdropout_and_save_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error for simple linear model:0.964594961658\n",
      "mean_absolute_error for simple linear model:0.7313176008\n"
     ]
    }
   ],
   "source": [
    "linear_model_prediction_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error for linear model with lrq:0.833489648878\n",
      "mean_absolute_error for linear model with lrq:0.7093573542\n"
     ]
    }
   ],
   "source": [
    "linear_model_with_lrq_prediction_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error for linear model with lrqdropout:0.829321837862\n",
      "mean_absolute_error for linear model with lrqdropout:0.68848776\n"
     ]
    }
   ],
   "source": [
    "linear_model_with_lrqdropout_prediction_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
